{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dc90822-09b3-4eae-8e87-5498765ac51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from src.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f5850857-8e6b-4baa-9a0d-2719d1ae198b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "TABLE_BRONZE_EXP = \"bronze_dev.sctr_emision.expuestos_bronze\"\n",
    "TABLE_BRONZE_CONT = \"bronze_dev.sctr_emision.contratantes_bronze\"\n",
    "\n",
    "TABLE_SILVER_EXP = \"silver_dev.sctr_emision.expuestos_silver\"\n",
    "TABLE_SILVER_CONT = \"silver_dev.sctr_emision.contratantes_silver\"\n",
    "\n",
    "COLS_NAM_EXP_FINAL = ['POLIZA','F_INI_VIGEN_POLIZA','F_FIN_VIGEN_POLIZA',\n",
    "                'CERTIFICADO','F_INI_COBERT','F_FIN_COBERT',\n",
    "                'TIPO_DOC','NUM_DOC','ULT_DIGI_DOC','EXPUESTO',\n",
    "                'YEAR_MOV','MONTH_MOV','FECHA_CARGA']\n",
    "                \n",
    "COLS_NAM_CONT_FINAL = ['POLIZA','TIPO_DOC','NUM_DOC_CONT','CONTRATANTE','YEAR_MOV','MONTH_MOV','FECHA_CARGA']\n",
    "\n",
    "set_config_spark(NUM_PARTITIONS)\n",
    "open_log(\"Silver\")\n",
    "\n",
    "logger.info(f\"‚ö™ Iniciando proceso Silver en Databricks. Cl√∫ster: {spark.conf.get('spark.databricks.clusterUsageTags.clusterId')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2862a655-b10d-437b-aa18-d632c61395e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_expuestos_silver(periodo) -> DataFrame:\n",
    "    try:\n",
    "        logger.info(f\"   üîç Leyendo Bronze Expuestos (Periodo: {periodo})...\")\n",
    "        \n",
    "        df = spark.read.table(TABLE_BRONZE_EXP) \\\n",
    "                 .filter(F.col(\"FECHA_CARGA\") == F.lit(periodo))\n",
    "\n",
    "        total_rows = df.count()\n",
    "        if total_rows == 0: \n",
    "            # logger.warning(f\"   ‚ö†Ô∏è La tabla Bronze Expuestos no contiene registros.\")\n",
    "            raise Exception(f\"La tabla Bronze Expuestos no contiene registros.\")\n",
    "        \n",
    "        logger.info(f\"   üîÑ Transformando Bronze Expuestos...\")\n",
    "        \n",
    "        def try_parse_dates(col_name):\n",
    "            return F.coalesce(*[F.to_date(F.substring(F.col(col_name), 1, 10), fmt) for fmt in DATE_FORMATS])\n",
    "\n",
    "        df_clean = (\n",
    "            df \n",
    "            .withColumn(\"NUM_DOC\", \n",
    "                F.translate(F.col(\"NUM_DOC\"), \"'\\\"_\", \"\") \n",
    "            )\n",
    "            .withColumn(\"ULT_DIGI_DOC\", F.expr(\"try_cast(substring(NUM_DOC, -1, 1) as INT)\"))\n",
    "            .withColumn(\"POLIZA\", F.col(\"POLIZA\").cast(DecimalType(scale=2)).cast(LongType()))\n",
    "            .withColumn(\"YEAR_MOV\", F.col(\"YEAR_MOV\").cast(DecimalType(scale=2)).cast(IntegerType())) \n",
    "            .withColumn(\"MONTH_MOV\", F.col(\"MONTH_MOV\").cast(DecimalType(scale=2)).cast(IntegerType())) \n",
    "            .withColumn(\"TIPO_DOC_RAW\", F.col(\"TIPO_DOC\").cast(DecimalType(scale=2)).cast(IntegerType())) \n",
    "            .withColumn(\"EXPUESTO\", \n",
    "                F.regexp_replace(\n",
    "                    F.trim(F.concat_ws(\" \", \n",
    "                        F.col(\"P_NOMBRE\"), F.col(\"S_NOMBRE\"), \n",
    "                        F.col(\"AP_PATERNO\"), F.col(\"AP_MATERNO\")\n",
    "                    )), \n",
    "                    \"  \", \" \"\n",
    "                )\n",
    "            ) \n",
    "            .withColumn(\"TIPO_DOC_DESC\", \n",
    "                F.when(F.col(\"TIPO_DOC_RAW\") == 1, \"DNI\")\n",
    "                .when(F.col(\"TIPO_DOC_RAW\") == 2, \"CE\")\n",
    "                .when(F.col(\"TIPO_DOC_RAW\") == 5, \"PAS\")\n",
    "                .otherwise(\"OTROS\")\n",
    "            ) \n",
    "            .withColumn(\"NUM_DOC_CLEAN\",\n",
    "                F.when(\n",
    "                    (F.length(F.col(\"NUM_DOC\")).isin([5, 6, 7])) & \n",
    "                    (F.col(\"NUM_DOC\").rlike(\"^\\\\d+$\")),\n",
    "                    F.lpad(F.col(\"NUM_DOC\"), 8, '0') # Zfill\n",
    "                ).otherwise(F.col(\"NUM_DOC\"))\n",
    "            ) \n",
    "            .drop(\"TIPO_DOC\", \"NUM_DOC\") \n",
    "            .withColumnRenamed(\"TIPO_DOC_DESC\", \"TIPO_DOC\") \n",
    "            .withColumnRenamed(\"NUM_DOC_CLEAN\", \"NUM_DOC\")\n",
    "        )\n",
    "\n",
    "        cols_date = ['F_INI_VIGEN_POLIZA','F_FIN_VIGEN_POLIZA','F_INI_COBERT','F_FIN_COBERT']\n",
    "        for c in cols_date:\n",
    "            df_clean = df_clean.withColumn(c, try_parse_dates(c))\n",
    "\n",
    "        df_clean = df_clean.filter(\n",
    "            F.col(\"POLIZA\").isNotNull()\n",
    "        )\n",
    "\n",
    "        df_clean = df_clean.withColumn(\"FECHA_CARGA\", F.to_date(F.from_utc_timestamp(F.current_timestamp(), 'America/Lima')))\n",
    "\n",
    "        df_final = df_clean.select(*COLS_NAM_EXP_FINAL) \\\n",
    "                    .distinct()\n",
    "                    # .dropDuplicates(COLS_NAM_EXP_FINAL)\n",
    "\n",
    "        total_rows = df_final.count()\n",
    "        logger.info(f\"   üìä Total Registros Guardados: {total_rows:,.0f}\")\n",
    "\n",
    "        return df_final\n",
    "    except Exception as e:\n",
    "        logger.error(f\"   ‚ùå Error en Transformaci√≥n Silver Expuestos. {e}\")\n",
    "        return None\n",
    "    \n",
    "def transform_contratantes_silver(periodo) -> DataFrame:\n",
    "    try:\n",
    "        logger.info(f\"   üîç Leyendo Bronze Contratantes (Periodo: {periodo})...\")\n",
    "\n",
    "        df = spark.read.table(TABLE_BRONZE_CONT) \\\n",
    "                 .filter(F.col(\"FECHA_CARGA\") == F.lit(periodo))\n",
    "\n",
    "        total_rows = df.count()\n",
    "        if total_rows == 0: \n",
    "            # logger.warning(f\"   ‚ö†Ô∏è La tabla Bronze Contratantes no contiene registros.\")\n",
    "            raise Exception(f\"La tabla Bronze Contratantes no contiene registros.\")\n",
    "        \n",
    "        logger.info(f\"   üîÑ Transformando Bronze Contratantes...\")\n",
    "\n",
    "        df_clean = (\n",
    "            df \n",
    "            .withColumn(\"NUM_DOC_CONT\", \n",
    "                F.translate(F.col(\"NUM_DOC_CONT\"), \"'\\\"_\", \"\") \n",
    "            )\n",
    "            .withColumn(\"POLIZA\", F.col(\"POLIZA\").cast(DecimalType(scale=2)).cast(LongType())) \\\n",
    "            .withColumn(\"YEAR_MOV\", F.col(\"YEAR_MOV\").cast(LongType()).cast(IntegerType())) \n",
    "            .withColumn(\"MONTH_MOV\", F.col(\"MONTH_MOV\").cast(LongType()).cast(IntegerType())) \n",
    "            .withColumn(\"TIPO_DOC_RAW\", F.col(\"TIPO_DOC\").cast(LongType()).cast(IntegerType())) \n",
    "            .withColumn(\"TIPO_DOC_DESC\", \n",
    "                F.when(F.col(\"TIPO_DOC_RAW\") == 1, \"DNI\")\n",
    "                .when(F.col(\"TIPO_DOC_RAW\") == 6, \"RUC\")\n",
    "                .otherwise(\"OTRO\")\n",
    "            ) \n",
    "            .withColumn(\"NUM_DOC_CONT_CLEAN\",\n",
    "                F.when(\n",
    "                    (F.col(\"TIPO_DOC_DESC\") == \"DNI\") &\n",
    "                    (F.length(F.col(\"NUM_DOC_CONT\")).isin([5, 6, 7])) &\n",
    "                    (F.col(\"NUM_DOC_CONT\").rlike(\"^\\\\d+$\")),\n",
    "                    F.lpad(F.col(\"NUM_DOC_CONT\"), 8, '0')\n",
    "                ).otherwise(F.col(\"NUM_DOC_CONT\"))\n",
    "            ) \n",
    "            .drop(\"TIPO_DOC\", \"NUM_DOC_CONT\") \n",
    "            .withColumnRenamed(\"TIPO_DOC_DESC\", \"TIPO_DOC\") \n",
    "            .withColumnRenamed(\"NUM_DOC_CONT_CLEAN\", \"NUM_DOC_CONT\")\n",
    "        )\n",
    "            \n",
    "        df_clean = df_clean.filter(\n",
    "            F.col(\"POLIZA\").isNotNull() & F.col(\"CONTRATANTE\").isNotNull()\n",
    "        )\n",
    "\n",
    "        df_clean = df_clean.withColumn(\"FECHA_CARGA\", F.to_date(F.from_utc_timestamp(F.current_timestamp(), 'America/Lima')))\n",
    "\n",
    "        df_final = df_clean.select(*COLS_NAM_CONT_FINAL) \\\n",
    "                    .distinct()\n",
    "                    # .dropDuplicates(COLS_NAM_CONT_FINAL)\n",
    "\n",
    "        total_rows = df_final.count()\n",
    "        logger.info(f\"   üìä Total Registros Guardados: {total_rows:,.0f}\")\n",
    "\n",
    "        return df_final\n",
    "    except Exception as e:\n",
    "        logger.error(f\"   ‚ùå Error en Transformaci√≥n Silver Contratantes. {e}\")\n",
    "        return None\n",
    "    \n",
    "def merge_to_delta(df_new: DataFrame, table_name: str, unique_keys: list) -> bool:\n",
    "    try:\n",
    "        logger.info(f\"   üîÑ Iniciando MERGE (Upsert) en {table_name}...\")\n",
    "        \n",
    "        condition = \" AND \".join([f\"t.{col} = s.{col}\" for col in unique_keys])\n",
    "\n",
    "        target_table = DeltaTable.forName(spark, table_name)\n",
    "        \n",
    "        (target_table.alias(\"t\")\n",
    "        .merge(\n",
    "            df_new.alias(\"s\"),\n",
    "            condition\n",
    "        )\n",
    "        .whenMatchedUpdateAll()\n",
    "        .whenNotMatchedInsertAll()\n",
    "        .execute()\n",
    "        )\n",
    "        logger.info(f\"   üíæ MERGE Guardado en {table_name}\")\n",
    "        last_operation = target_table.history(1).select(\"operationMetrics\").collect()[0][0]\n",
    "        num_inserted = last_operation.get(\"numTargetRowsInserted\", \"0\")\n",
    "        num_updated = last_operation.get(\"numTargetRowsUpdated\", \"0\")\n",
    "        logger.info(f\"   üìà Merge Reporte: Insertados={num_inserted}, Actualizados={num_updated}\")\n",
    "\n",
    "        print(target_table.detail())\n",
    "        total_rows = target_table.toDF().count()\n",
    "        # total_rows = int(target_table.detail().select(\"numRecords\").collect()[0][0])\n",
    "        logger.info(f\"   üìä Total Registros Guardados (Post Merge): {total_rows:,.0f}\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"   ‚ùå Error en Merge Delta ({table_name}). {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c1ba262-59d6-4857-adbf-1d70a6cd7eff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def start_process(df: DataFrame|None, process: str, table_name: str, unique_keys: list) -> bool:\n",
    "    status = False\n",
    "    condition = \", \".join([col for col in unique_keys])\n",
    "\n",
    "    if validate_table_delta(table_name):\n",
    "        df_count = spark.read.table(table_name).count()\n",
    "        if df_count > 0:\n",
    "            status = merge_to_delta(df, table_name, unique_keys)\n",
    "            if not status:\n",
    "                raise Exception(f\"El proceso fall√≥ en el merge de la data transformada de {process} en la tabla {table_name}.\")\n",
    "        else:\n",
    "            status = save_to_table_delta(df, table_name, \"overwrite\", \"false\")\n",
    "    else:\n",
    "        status = save_to_table_delta(df, table_name, \"overwrite\", \"false\")\n",
    "\n",
    "    if validate_table_delta(table_name, False):\n",
    "        logger.info(f\"   üßπ Optimizando tabla Silver {process}...\")\n",
    "        spark.sql(f\"OPTIMIZE {table_name} ZORDER BY ({condition})\")\n",
    "\n",
    "        logger.info(f\"   üìã Analizando tabla Silver {process}...\")\n",
    "        spark.sql(f\"ANALYZE TABLE {table_name} COMPUTE STATISTICS FOR COLUMNS POLIZA\")\n",
    "        \n",
    "        status = True\n",
    "\n",
    "    return status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48139ac0-528d-410e-a45c-94c58f7506e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "RUN_EXPUESTOS = True\n",
    "RUN_CONTRATANTES = True\n",
    "if IS_CLOUD:\n",
    "    dbutils.widgets.text(\"ON_DEMAND\", \"False\")\n",
    "    dbutils.widgets.text(\"DATE_PROCESS\", \"\") \n",
    "\n",
    "    ON_DEMAND = dbutils.widgets.get(\"ON_DEMAND\").lower() == 'true'\n",
    "    DATE_PROCESS = dbutils.widgets.get(\"DATE_PROCESS\")\n",
    "else:\n",
    "    ON_DEMAND = False\n",
    "    DATE_PROCESS = \"\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        periodo_param = datetime.strptime(DATE_PROCESS,\"%Y-%m-%d\").date() if ON_DEMAND else PERIODO\n",
    "\n",
    "        if RUN_EXPUESTOS:\n",
    "            df_exp_silver = transform_expuestos_silver(periodo_param)\n",
    "            if df_exp_silver is None:\n",
    "                raise Exception(\"El proceso fall√≥ en la transformaci√≥n de la data de Expuestos de la capa bronze.\")\n",
    "            \n",
    "            keys_exp = ['POLIZA', 'CERTIFICADO', 'NUM_DOC', 'YEAR_MOV', 'MONTH_MOV'] \n",
    "            success_process = start_process(df_exp_silver, \"Expuestos\", TABLE_SILVER_EXP, keys_exp)\n",
    "            if not success_process:\n",
    "                raise Exception(f\"El proceso fall√≥ al guardar la informaci√≥n en la tabla delta {TABLE_SILVER_EXP}\")\n",
    "\n",
    "        if RUN_CONTRATANTES:\n",
    "            df_cont_silver = transform_contratantes_silver(periodo_param)\n",
    "            if df_cont_silver is None:\n",
    "                raise Exception(\"El proceso fall√≥ en la transformaci√≥n de la data de Contratantes de la capa bronze.\")\n",
    "            \n",
    "            keys_cont = ['POLIZA', 'NUM_DOC_CONT', 'YEAR_MOV', 'MONTH_MOV']\n",
    "            success_process = start_process(df_cont_silver, \"Contratantes\", TABLE_SILVER_CONT, keys_cont)\n",
    "            if not success_process:\n",
    "                raise Exception(f\"El proceso fall√≥ al guardar la informaci√≥n en la tabla delta {TABLE_SILVER_CONT}\")\n",
    "\n",
    "        logger.success(\"üèÅ Ejecuci√≥n Completa: Proceso Silver Finalizado con √©xito.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Error cr√≠tico en proceso Silver. {e}\")\n",
    "        raise e\n",
    "    finally:\n",
    "        finalize_process()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LoadSilver",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Proyecto_ETL_Emision_SCTR_Databricks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
